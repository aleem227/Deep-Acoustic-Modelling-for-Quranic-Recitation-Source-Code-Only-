{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "AL_FALAQ =  np.load('al_falaq_mean.npy')\n",
    "AL_FIL =  np.load('al_fil_mean.npy')\n",
    "AL_IKHLAS =  np.load('al_ikhlas_mean.npy')\n",
    "AL_KAFIRUN =  np.load('al_kafirun_mean.npy')\n",
    "AL_KAUTHAR =  np.load('al_kauthar_mean.npy')\n",
    "AL_MASAD =  np.load('al_masad_mean.npy')\n",
    "AL_MAUN =  np.load('al_maun_mean.npy')\n",
    "AL_QURAISH =  np.load('al_quraish_mean.npy')\n",
    "AN_NAS =  np.load('an_nas_mean.npy')\n",
    "AN_NASR =  np.load('an_nasr_mean.npy')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcc_features_extractor_1sec(file):\n",
    "    # audio, sample_rate = librosa.load(file_name) \n",
    "    # mfccs_features = librosa.feature.mfcc(y=audio, sr=16000, n_mfcc=40)\n",
    "    # mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
    "    \n",
    "    y, sr = librosa.load(file, sr=16000)\n",
    "    \n",
    "    y = y[:192000]  #12 Secs for all audios\n",
    "    zero_padding = np.zeros(192000 - y.shape[0], dtype=np.float32)\n",
    "    y = np.concatenate([y, zero_padding])   \n",
    "\n",
    "    # Define window size and hop length\n",
    "    win_length = int(sr * 1) # 1 second window\n",
    "    hop_length = int(win_length / 2) # 50% overlap\n",
    "\n",
    "    # Extract MFCC features for each window\n",
    "    mfccs = []\n",
    "    for i in range(0, len(y)-win_length, hop_length):\n",
    "        mfcc = librosa.feature.mfcc(y=y[i:i+win_length], sr=sr, n_mfcc=40)\n",
    "        mfccs.append(mfcc)\n",
    "\n",
    "    # Combine MFCC features for all windows\n",
    "    mfccs = np.concatenate(mfccs, axis=1)\n",
    "    mfccs = mfccs.T\n",
    "\n",
    "    # Return final MFCC features\n",
    "    return mfccs\n",
    "\n",
    "    \n",
    "    # return mfccs_scaled_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mfcc_data_by_fold = {}\n",
    "\n",
    "# # Iterate through the DataFrame and extract MFCC features\n",
    "# for index_num, row in tqdm(metadata.iterrows()):\n",
    "#     file_name = os.path.join(os.path.abspath(audio_dataset_path), 'fold' + str(row[\"fold\"]) + '/', str(row[\"slice_file_name\"]))\n",
    "#     final_class_labels = row[\"class\"]\n",
    "\n",
    "#     # MFCC Features Extraction\n",
    "#     mfcc_data = mfcc_features_extractor_1sec(file_name)\n",
    "    \n",
    "#     # Store the MFCC data in the dictionary by fold number\n",
    "#     fold_num = row[\"fold\"]\n",
    "#     if fold_num not in mfcc_data_by_fold:\n",
    "#         mfcc_data_by_fold[fold_num] = {\n",
    "#             \"data\": [],\n",
    "#             \"labels\": []\n",
    "#         }\n",
    "#     mfcc_data_by_fold[fold_num][\"data\"].append(mfcc_data)\n",
    "#     mfcc_data_by_fold[fold_num][\"labels\"].append(final_class_labels)\n",
    "\n",
    "# # Now, convert the data in mfcc_data_by_fold to NumPy arrays\n",
    "# for fold_num, data_dict in mfcc_data_by_fold.items():\n",
    "#     data_dict[\"data\"] = np.array(data_dict[\"data\"])\n",
    "#     data_dict[\"labels\"] = np.array(data_dict[\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'C:/Users/aleem/Desktop/Currentlyworking_New_extracted audio wav after cleaning then augmentation/sliding_window_1_sec/data/notsure.wav'\n",
    "\n",
    "\n",
    "mfcc_extracted_features_single=[]\n",
    "\n",
    "mfcc_extracted_features_single= mfcc_features_extractor_1sec(file_name)\n",
    "\n",
    "mfcc_extracted_features_single = np.array(mfcc_extracted_features_single)\n",
    "\n",
    "mfcc_extracted_features_single = mfcc_extracted_features_single.reshape((1, 704, 40, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-2.6725391e+02],\n",
       "         [ 2.3117771e+01],\n",
       "         [ 5.1828484e+01],\n",
       "         ...,\n",
       "         [-2.3901701e+00],\n",
       "         [-2.7474132e+00],\n",
       "         [-6.3987398e+00]],\n",
       "\n",
       "        [[-1.9216940e+02],\n",
       "         [ 2.7146608e+01],\n",
       "         [ 4.3217205e+01],\n",
       "         ...,\n",
       "         [ 7.4055505e-01],\n",
       "         [-2.9070754e+00],\n",
       "         [-7.8788406e-01]],\n",
       "\n",
       "        [[-1.7306792e+02],\n",
       "         [ 2.8482719e+01],\n",
       "         [ 3.8894516e+01],\n",
       "         ...,\n",
       "         [ 1.3919991e+00],\n",
       "         [-6.4232373e+00],\n",
       "         [ 3.8830898e+00]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[-1.1313708e+03],\n",
       "         [ 0.0000000e+00],\n",
       "         [ 0.0000000e+00],\n",
       "         ...,\n",
       "         [ 0.0000000e+00],\n",
       "         [ 0.0000000e+00],\n",
       "         [ 0.0000000e+00]],\n",
       "\n",
       "        [[-1.1313708e+03],\n",
       "         [ 0.0000000e+00],\n",
       "         [ 0.0000000e+00],\n",
       "         ...,\n",
       "         [ 0.0000000e+00],\n",
       "         [ 0.0000000e+00],\n",
       "         [ 0.0000000e+00]],\n",
       "\n",
       "        [[-1.1313708e+03],\n",
       "         [ 0.0000000e+00],\n",
       "         [ 0.0000000e+00],\n",
       "         ...,\n",
       "         [ 0.0000000e+00],\n",
       "         [ 0.0000000e+00],\n",
       "         [ 0.0000000e+00]]]], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfcc_extracted_features_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 180ms/step\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = load_model('Model_CNN2D_startwithnumpylengthsamemfcc_1sec_4032files_90_10_size_result 100_96.29.h5')\n",
    "\n",
    "# Get the name of the intermediate layer from the loaded model summary\n",
    "intermediate_layer_name = 'dense'\n",
    "\n",
    "# Find the index of the intermediate layer in the model's layers list\n",
    "intermediate_layer_index = [i for i, layer in enumerate(loaded_model.layers) if layer.name == intermediate_layer_name][0]\n",
    "\n",
    "# Define a new model that includes layers up to the intermediate layer\n",
    "intermediate_layer_model = Model(inputs=loaded_model.input,\n",
    "                                  outputs=loaded_model.layers[intermediate_layer_index].output)\n",
    "\n",
    "# Assuming you already have mfcc_extracted_features of shape (704, 40, 1)\n",
    "# Replace this with your actual input data\n",
    "\n",
    "# Predict the intermediate layer output for the input data\n",
    "intermediate_output = intermediate_layer_model.predict(mfcc_extracted_features_single)\n",
    "\n",
    "# Now, intermediate_output contains the intermediate layer output for mfcc_extracted_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9998561 ,  1.        , -0.952353  , ...,  0.9999996 ,\n",
       "        -0.9037282 , -0.99999493]], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1024)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intermediate_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closest array name: AL_KAFIRUN\n",
      "Closest index within the array: 5\n",
      "Closest distance: 20.244651794433594\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the 10 arrays and store them in a dictionary\n",
    "arrays = {\n",
    "    'AL_FALAQ': np.load('al_falaq_mean.npy'),\n",
    "    'AL_FIL': np.load('al_fil_mean.npy'),\n",
    "    'AL_IKHLAS': np.load('al_ikhlas_mean.npy'),\n",
    "    'AL_KAFIRUN': np.load('al_kafirun_mean.npy'),\n",
    "    'AL_KAUTHAR': np.load('al_kauthar_mean.npy'),\n",
    "    'AL_MASAD': np.load('al_masad_mean.npy'),\n",
    "    'AL_MAUN': np.load('al_maun_mean.npy'),\n",
    "    'AL_QURAISH': np.load('al_quraish_mean.npy'),\n",
    "    'AN_NAS': np.load('an_nas_mean.npy'),\n",
    "    'AN_NASR': np.load('an_nasr_mean.npy')\n",
    "}\n",
    "\n",
    "\n",
    "# Assuming you already have the 'arrays' dictionary defined as shown in your question\n",
    "# Also assuming 'intermediate_output' is defined somewhere\n",
    "\n",
    "closest_distance = float('inf')  # Initialize closest_distance to positive infinity\n",
    "closest_array = None\n",
    "closest_array_name = None\n",
    "closest_index_within_array = None\n",
    "\n",
    "# Define the names of the arrays you want to compare\n",
    "array_names_to_compare = ['AL_FALAQ', 'AL_FIL', 'AL_IKHLAS', 'AL_KAFIRUN', 'AL_KAUTHAR',\n",
    "                          'AL_MASAD', 'AL_MAUN', 'AL_QURAISH', 'AN_NAS', 'AN_NASR']\n",
    "\n",
    "# Loop through the array names and calculate distances\n",
    "for array_name in array_names_to_compare:\n",
    "    array = arrays.get(array_name)\n",
    "    if array is not None:\n",
    "        distances = np.linalg.norm(array - intermediate_output, axis=1)\n",
    "        closest_index = np.argmin(distances)\n",
    "        closest_distance_for_array = distances[closest_index]\n",
    "\n",
    "        if closest_distance_for_array < closest_distance:\n",
    "            closest_distance = closest_distance_for_array\n",
    "            closest_array = array\n",
    "            closest_array_name = array_name\n",
    "            closest_index_within_array = closest_index\n",
    "\n",
    "# Print the index and name of the closest array and its closest index\n",
    "if closest_array_name is not None:\n",
    "    print(f\"Closest array name: {closest_array_name}\")\n",
    "    print(f\"Closest index within the array: {closest_index_within_array+1}\")\n",
    "    print(f\"Closest distance: {closest_distance}\")\n",
    "else:\n",
    "    print(\"No valid closest array found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
