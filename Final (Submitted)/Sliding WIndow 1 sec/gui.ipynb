{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleem\\AppData\\Roaming\\Python\\Python39\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.3, Python 3.9.13)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "1/1 [==============================] - 0s 411ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aleem\\AppData\\Local\\Temp\\ipykernel_18568\\3917020190.py:112: FutureWarning: get_duration() keyword argument 'filename' has been renamed to 'path' in version 0.10.0.\n",
      "\tThis alias will be removed in version 1.0.\n",
      "  audio_length = librosa.get_duration(filename=file_name)  # Get audio length in seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "from keras.models import load_model\n",
    "from keras.models import Model\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter import ttk \n",
    "from pydub import AudioSegment\n",
    "import pygame\n",
    "\n",
    "# Initialize pygame for audio playback\n",
    "pygame.mixer.init()\n",
    "\n",
    "# Function to extract MFCC features from a WAV file\n",
    "def mfcc_features_extractor_1sec(file):\n",
    "    y, sr = librosa.load(file, sr=16000)\n",
    "    y = y[:192000]  # 12 seconds for all audios\n",
    "    zero_padding = np.zeros(192000 - y.shape[0], dtype=np.float32)\n",
    "    y = np.concatenate([y, zero_padding])\n",
    "\n",
    "    # Define window size and hop length\n",
    "    win_length = int(sr * 1)  # 1 second window\n",
    "    hop_length = int(win_length / 2)  # 50% overlap\n",
    "\n",
    "    # Extract MFCC features for each window\n",
    "    mfccs = []\n",
    "    for i in range(0, len(y) - win_length, hop_length):\n",
    "        mfcc = librosa.feature.mfcc(y=y[i:i + win_length], sr=sr, n_mfcc=40)\n",
    "        mfccs.append(mfcc)\n",
    "\n",
    "    # Combine MFCC features for all windows\n",
    "    mfccs = np.concatenate(mfccs, axis=1)\n",
    "    mfccs = mfccs.T\n",
    "\n",
    "    # Return final MFCC features\n",
    "    return mfccs\n",
    "\n",
    "# Function to calculate the closest array\n",
    "def find_closest_array(intermediate_output, arrays):\n",
    "    closest_distance = float('inf')  # Initialize closest_distance to positive infinity\n",
    "    closest_array = None\n",
    "    closest_array_name = None\n",
    "    closest_index_within_array = None\n",
    "\n",
    "    # Define the names of the arrays you want to compare\n",
    "    array_names_to_compare = ['AL_FALAQ', 'AL_FIL', 'AL_IKHLAS', 'AL_KAFIRUN', 'AL_KAUTHAR',\n",
    "                              'AL_MASAD', 'AL_MAUN', 'AL_QURAISH', 'AN_NAS', 'AN_NASR']\n",
    "\n",
    "    # Loop through the array names and calculate distances\n",
    "    for array_name in array_names_to_compare:\n",
    "        array = arrays.get(array_name)\n",
    "        if array is not None:\n",
    "            distances = np.linalg.norm(array - intermediate_output, axis=1)\n",
    "            closest_index = np.argmin(distances)\n",
    "            closest_distance_for_array = distances[closest_index]\n",
    "\n",
    "            if closest_distance_for_array < closest_distance:\n",
    "                closest_distance = closest_distance_for_array\n",
    "                closest_array = array\n",
    "                closest_array_name = array_name\n",
    "                closest_index_within_array = closest_index\n",
    "\n",
    "    return closest_array_name, closest_index_within_array, closest_distance\n",
    "\n",
    "# Function to process the selected file\n",
    "def process_selected_file():\n",
    "    file_name = filedialog.askopenfilename(\n",
    "        title=\"Select a WAV file\",\n",
    "        filetypes=[(\"WAV files\", \"*.wav\")]\n",
    "    )\n",
    "\n",
    "    if file_name:\n",
    "        status_label.config(text=\"Processing...\")\n",
    "        root.update_idletasks()  # Update the GUI to show the \"Processing...\" message\n",
    "\n",
    "        # Extract MFCC features from the selected file\n",
    "        mfcc_extracted_features_single = mfcc_features_extractor_1sec(file_name)\n",
    "        mfcc_extracted_features_single = np.array(mfcc_extracted_features_single)\n",
    "        mfcc_extracted_features_single = mfcc_extracted_features_single.reshape((1, 704, 40, 1))\n",
    "\n",
    "        # Load the saved model\n",
    "        loaded_model = load_model('Model_CNN2D_startwithnumpylengthsamemfcc_1sec_4032files_90_10_size_result 100_96.29.h5')\n",
    "\n",
    "        # Get the intermediate layer output\n",
    "        intermediate_layer_name = 'dense'\n",
    "        intermediate_layer_index = [i for i, layer in enumerate(loaded_model.layers) if layer.name == intermediate_layer_name][0]\n",
    "        intermediate_layer_model = Model(inputs=loaded_model.input, outputs=loaded_model.layers[intermediate_layer_index].output)\n",
    "        intermediate_output = intermediate_layer_model.predict(mfcc_extracted_features_single)\n",
    "\n",
    "        # Load the arrays\n",
    "        arrays = {\n",
    "            'AL_FALAQ': np.load('al_falaq_mean.npy'),\n",
    "            'AL_FIL': np.load('al_fil_mean.npy'),\n",
    "            'AL_IKHLAS': np.load('al_ikhlas_mean.npy'),\n",
    "            'AL_KAFIRUN': np.load('al_kafirun_mean.npy'),\n",
    "            'AL_KAUTHAR': np.load('al_kauthar_mean.npy'),\n",
    "            'AL_MASAD': np.load('al_masad_mean.npy'),\n",
    "            'AL_MAUN': np.load('al_maun_mean.npy'),\n",
    "            'AL_QURAISH': np.load('al_quraish_mean.npy'),\n",
    "            'AN_NAS': np.load('an_nas_mean.npy'),\n",
    "            'AN_NASR': np.load('an_nasr_mean.npy')\n",
    "        }\n",
    "\n",
    "        # Find the closest array\n",
    "        closest_array_name, closest_index_within_array, closest_distance = find_closest_array(intermediate_output, arrays)\n",
    "\n",
    "        # Display the result\n",
    "        result_label.config(text=f\"Surah Name: {closest_array_name}\\nIndex of Surah: {closest_index_within_array+1}\\n{closest_array_name}:{closest_index_within_array+1}\")\n",
    "        status_label.config(text=\"Completed\")\n",
    "\n",
    "        # Add audio progress bar\n",
    "        audio_length = librosa.get_duration(filename=file_name)  # Get audio length in seconds\n",
    "        audio_progress_bar[\"maximum\"] = int(audio_length)\n",
    "        audio_progress_bar[\"value\"] = 0  # Initialize progress to 0\n",
    "\n",
    "        # Play the selected audio file\n",
    "        play_audio(file_name)\n",
    "\n",
    "    else:\n",
    "        status_label.config(text=\"No file selected.\")\n",
    "\n",
    "# Function to play the selected audio file\n",
    "def play_audio(file_path):\n",
    "    audio = AudioSegment.from_wav(file_path)\n",
    "    pygame.mixer.music.load(file_path)\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    # Update the progress bar while playing\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        current_time = pygame.mixer.music.get_pos() // 1000  # Convert milliseconds to seconds\n",
    "        audio_progress_bar[\"value\"] = current_time\n",
    "        root.update_idletasks()  # Update the GUI\n",
    "\n",
    "# Create the tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"Deep Acoustic Modelling for Quranic Recitation\")\n",
    "root.geometry(\"1024x768\")  # Set window size to 1024x768\n",
    "\n",
    "# Create a header label\n",
    "header_label = tk.Label(root, text=\"Deep Acoustic Modelling for Quranic Recitation\", font=(\"Helvetica\", 24))\n",
    "header_label.pack(pady=80)\n",
    "\n",
    "# Create a separator between left and right sections\n",
    "separator = ttk.Separator(root, orient=\"vertical\")\n",
    "separator.pack(fill=\"y\", side=\"left\")\n",
    "\n",
    "# Create a left frame for the file selection button and audio progress bar\n",
    "left_frame = tk.Frame(root, width=960, height=1080, padx=200, pady=20)\n",
    "left_frame.pack(side=\"left\")\n",
    "\n",
    "# Create a button to trigger file selection\n",
    "select_file_button = tk.Button(left_frame, text=\"Choose WAV\", command=process_selected_file)\n",
    "select_file_button.pack(pady=20)\n",
    "\n",
    "# Create an audio progress bar\n",
    "audio_progress_bar = ttk.Progressbar(left_frame, orient=\"horizontal\", length=300, mode=\"determinate\")\n",
    "audio_progress_bar.pack(pady=20)\n",
    "\n",
    "# Create a right frame for the result and status\n",
    "right_frame = tk.Frame(root, width=960, height=1080, padx=200, pady=20)\n",
    "right_frame.pack(side=\"right\")\n",
    "\n",
    "# Create a label to display the result\n",
    "result_label = tk.Label(right_frame, text=\"\", font=(\"Helvetica\", 16))\n",
    "result_label.pack()\n",
    "\n",
    "# Create a label to display the status\n",
    "status_label = tk.Label(right_frame, text=\"\", font=(\"Helvetica\", 14))\n",
    "status_label.pack()\n",
    "\n",
    "# Start the tkinter main loop\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
